{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f253c6ca-78c2-4bd4-b5f0-7ebb2dc6bbd7",
   "metadata": {},
   "source": [
    "# Trabajo final PLN\n",
    "\n",
    "Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047b4c48-008c-4d90-979a-9771292e42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Flask-Bootstrap\n",
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2060f4e-0d4a-40c0-915f-a4dafff4ba84",
   "metadata": {},
   "source": [
    "## 1. Recolección de datos\n",
    "\n",
    "Para la recolección de datos se usó la API tweepy, estra api permite interactuar con twitter para la publicación y recolección de tweets, en nuestro caso lo usaremos para extraer datos de publicaciones por fechas a partir de un topic.\n",
    "\n",
    "Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d77feb-cbab-45f3-b4f5-fe3a5812efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "from flask import Flask, render_template,request,url_for,Response\n",
    "from flask_bootstrap import Bootstrap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "#plt.style.use('seaborn')\n",
    "\n",
    "from textblob import TextBlob,Word \n",
    "import random \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60ad56-2861-4beb-8def-8781789f4db6",
   "metadata": {},
   "source": [
    "Credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d68954-9b5b-4cbb-8c79-b06e9fa314b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'PCAI4xyHdvwVcwfcw1FuWslrM'\n",
    "consumer_secret= 'PgOnYL2cMqUcoscPR8t9rGEFEc65PhBahVfOYLJxR7V2mwPnyq'\n",
    "access_token= '3158149931-HkzDndqf0GxdpGt6bVkySL0ZXCevxdeotmEeVbJ'\n",
    "access_token_secret= 'jL7WnaaCphpVtyavexHRlZCu9fkuZkw6J0T4OBXMRHdER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79af27b5-1500-42f9-924c-e821b23fe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777333e-4a24-40da-b669-80e24a5385a9",
   "metadata": {},
   "source": [
    "Funcion para acceder por fecha a tweets mediante api tweepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c6101f-3887-4b31-9d19-dac747b8d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_days(search_words, month, day):\n",
    "\n",
    "    dt = datetime.datetime.today()\n",
    "    year = dt.year\n",
    "    date_since = datetime.datetime(year, month, day, 0, 0, 0)\n",
    "    date_until =   datetime.datetime(year, month, day+1, 0, 0, 0)\n",
    "\n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since,\n",
    "                       until=date_until,\n",
    "                       result_type=\"recent\",\n",
    "                       sleep_on_rate_limit=False\n",
    "                       ).items(25)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3820f2c-c4b4-44d4-8711-51e1b2303b5f",
   "metadata": {},
   "source": [
    "Funcion para recopilar tweets en dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c48e338-aec7-4388-87bf-88c9eefaa06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_1(search_words):\n",
    "\n",
    "    df = pd.DataFrame(columns=['date', 'user', 'text'])\n",
    "\n",
    "    dt = datetime.datetime.today()\n",
    "    days = dt.day\n",
    "\n",
    "    for day in range(days-25,days):\n",
    "        data = []\n",
    "        if day <= 0:\n",
    "            day = 30 + day\n",
    "            month = dt.month - 1\n",
    "            #print(month, day)\n",
    "            tweets = tweet_days(search_words, month, day)\n",
    "\n",
    "        else:\n",
    "            month = dt.month\n",
    "            #print(month,day)\n",
    "            tweets = tweet_days(search_words, month, day)\n",
    "\n",
    "        data = [[tweet.created_at, tweet.user.screen_name, tweet.text] for tweet in tweets]\n",
    "        df2 = pd.DataFrame(data = data, columns=['date', 'user', 'text'])\n",
    "        df = df.append(df2, ignore_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f1185f-6b68-446f-9748-1e6427993095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search_words):\n",
    "\n",
    "    df = pd.DataFrame(columns=['date', 'user', 'text'])\n",
    "\n",
    "    date_since = datetime.datetime(2021, 7, 1, 0, 0, 0)\n",
    "    #date_until =   datetime.datetime(year, month, day+1, 0, 0, 0)\n",
    "\n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since,\n",
    "                       #until=date_until,\n",
    "                       result_type=\"recent\",\n",
    "                       sleep_on_rate_limit=False\n",
    "                       ).items(1000)\n",
    "    data = [[tweet.created_at, tweet.user.screen_name, tweet.text] for tweet in tweets]\n",
    "    df = pd.DataFrame(data = data, columns=['date', 'user', 'text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7fa19-62bb-4bcb-8801-26a35e820475",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento\n",
    "\n",
    "Se usó la libreria NLTK y re, el preprocesamiento consiste en:\n",
    "\n",
    "- Cambio de mayusculas a minusculas.\n",
    "- Eliminación de menciones \"@...\", retweets \"RT @...\" y enlaces webs \"htps://...\" \n",
    "- Eliminación de stopwords\n",
    "- Eliminación de emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ed1ea-b68d-4762-a300-b89f206cfa49",
   "metadata": {},
   "source": [
    "Importación de librerias para preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f39cd6-bf24-4686-a639-8b15de8dbec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a6a50-13b7-4802-8698-2e853849562a",
   "metadata": {},
   "source": [
    "Función para preprocesamiento de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4aaf029-c978-40ee-8978-264d214ca639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prep(text:str):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    \n",
    "    tokens = [] \n",
    "    text = re.sub('https\\S+', '', text)\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "\n",
    "    text = regrex_pattern.sub(r'',text)\n",
    "    #text = re.sub('Replying to \\n@\\S+', '', text)\n",
    "    text = re.sub('RT @\\S+', '', text)\n",
    "    text = re.sub('@\\S+', '', text)\n",
    "    text = re.sub('#\\S+', '', text)\n",
    "\n",
    "    for w in word_tokenize(text):\n",
    "        w = w.lower()\n",
    "        if ((re.search('[a-zA-Z]', w)) and (w not in stopwords)): tokens.append(w)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11b6bce-abe6-4705-bea6-76ab8f1b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text:str):\n",
    "    blob = TextBlob(text)\n",
    "    blob_sentiment = blob.sentiment.polarity\n",
    "    if blob_sentiment >= 0:\n",
    "        blob_sentiment = 1\n",
    "    else:\n",
    "        blob_sentiment = 0\n",
    "    return blob_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a917c152-60cc-405a-ab4a-67be53fa20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_svm(text:str):\n",
    "    clf = pickle.load(open('clf.pkl', 'rb'))\n",
    "    tfidf = pickle.load(open('tfidf.pkl', 'rb'))\n",
    "    sentiment = clf.predict(tfidf.transform([text]))\n",
    "    return sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8523bb-41d7-4a2c-86e2-55b424a56a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting templates/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile templates/index.html\n",
    "{% extends \"bootstrap/base.html\" %}\n",
    "\n",
    "{% block content %}\n",
    "\n",
    "<style type=\"text/css\">\n",
    "        body{\n",
    "    font:15px/1.5 Arial, Helvetica,sans-serif;\n",
    "}\n",
    "        .spinner-1:before{\n",
    "            content: \"\";\n",
    "            box-sizing: border-box;\n",
    "            position: absolute;\n",
    "            top:50%;\n",
    "            left: 50%;\n",
    "            height: 60px;\n",
    "            width: 60px;\n",
    "            margin-top: -30px;\n",
    "            margin-left: -30px;\n",
    "            border-radius: 50%;\n",
    "            border:6px solid transparent;\n",
    "            border-top-color: blue;\n",
    "            animation: spinner 0.7s linear infinite;\n",
    "        }\n",
    "                 .jumbotron text-center{\n",
    "                  background-color:red;\n",
    "                  text-color:white;\n",
    "                   }\n",
    "        @keyframes spinner {\n",
    "            to {\n",
    "                transform: rotate(360deg);\n",
    "            }\n",
    "\n",
    "        }\n",
    "        li { background-color:#BDBDBD; }\n",
    "        li:nth-child(odd) { background-color:green; }\n",
    "        </style>\n",
    "\n",
    "\n",
    "<div class=\"container\">\n",
    "    <div class=\"text-center\">\n",
    "        <h3><b>TWITTER SENTIMENT ANALYSIS NLP<b></h3>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"container jumbotron\">\n",
    "    <form method=\"POST\" action=\"{{ url_for('analyse')}}\" id=\"myForm\">\n",
    "        \n",
    "    <label ><strong>Enter topic<strong></label><br>\n",
    "    <textarea class=\"form-control\" rows=\"1\" cols=\"10\" name=\"rawtext\"></textarea><br>\n",
    "\n",
    "    <input type=\"submit\" onclick=\"myAnalyser()\" value=\"Submit\" class=\"btn btn-primary \">\n",
    "    <input type=\"button\" onclick=\"myFunction()\" value=\"Clear\" class=\"btn btn-outline-dark\">\n",
    "\n",
    "    <a href=\"{{ url_for('index')}}\" type=\"button\" class=\"btn btn-danger\" > Reset</a>\n",
    "    \n",
    "    </form>\n",
    "    \n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "<div class=\"main\">\n",
    "<div class=\"container\">\n",
    "    <div class=\"card\">\n",
    "\n",
    "  <div class=\"card-body\">\n",
    "    <div class=\"card-text\"> \n",
    "        <h5>Topic</h5>\n",
    "        <p style=\"color:#0091EA;font-family:sans-serif;\">{{ received_text }}</p>\n",
    "        <hr/>\n",
    "        <li class=\"list-group-item list-group-item-info\"><span style=\"color:black\">Tweets: {{n_twwets}}</span></li>\n",
    "\n",
    "        <hr/>\n",
    "<br/>\n",
    "    <p>Time Elapsed: <span style=\"color:#0091EA;\">{{ final_time }} </span> seconds to analyse</p>\n",
    "       \n",
    "  </div>\n",
    "  <div class=\"card-footer text-muted\">\n",
    "    <table class=\"table table-striped table-dark\" >\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th scope=\"col\">Tweet</th>\n",
    "          <th scope=\"col\">Polarity</th>\n",
    "          <th scope=\"col\">Polarity_svm</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        {% for row in data %}\n",
    "        <tr>\n",
    "          <td>{{row['text']}}</td>\n",
    "          <td>{{row['polarity']}}</td>\n",
    "          <td>{{row['polarity_svm']}}</td>\n",
    "        {% endfor %}\n",
    "        </tr>\n",
    "    </tbody></table>\n",
    " \n",
    "    <div class=\"container\">\n",
    "            \n",
    "        <div class=\"text-center\">\n",
    "\n",
    "            <h4>Wordcloud</h4>\n",
    "\n",
    "            <img src={{url_wc}} alt=\"Chart_wc\" width=\"800\" >\n",
    "            \n",
    "        </div>\n",
    "            \n",
    "        <div class=\"text-center\">\n",
    "            <h4>{{name}}</h4>\n",
    "\n",
    "            <img src={{url}} alt=\"Chart\" width=\"700\" >\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "    \n",
    "</div>\n",
    "</div>\n",
    "\n",
    "\n",
    "{% endblock %}\n",
    "\n",
    "\n",
    "<!-- Scripts starts here -->\n",
    "{% block scripts %}\n",
    "\n",
    "{{ super() }}\n",
    "\n",
    "<script>\n",
    "function myFunction() {\n",
    "    document.getElementById(\"myForm\").reset();\n",
    "}\n",
    "</script>\n",
    "<script>\n",
    "function myAnalyser() {\n",
    "    document.querySelector('.main div').style.display = 'none';\n",
    "    //Hide the main division\n",
    "    document.querySelector('.main').classList.add('spinner-1');\n",
    "    // Server request\n",
    "    setTimeout(() => {\n",
    "    document.querySelector('.main').classList.remove('spinner-1');\n",
    "    //Remove the animation\n",
    "    document.querySelector('.main div').style.display = 'block';\n",
    "    //Show the main division\n",
    "    },15000);//Number of seconds to last\n",
    "}\n",
    "</script>\n",
    "\n",
    "<!-- Prevent it from being overwritten -->\n",
    "\n",
    "{% endblock %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6b9bbd-c13b-4e61-b083-2d876f6bc140",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "Bootstrap(app)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/analyse',methods=['POST'])\n",
    "def analyse():\n",
    "    summary = ''\n",
    "    final_time = ''\n",
    "    start = time.time()\n",
    "    if request.method == 'POST':\n",
    "        topic = request.form['rawtext']\n",
    "        \n",
    "        #NLP Stuff\n",
    "        df = get_tweets(topic)\n",
    "        df['text_prep'] = df.text.apply(text_prep)\n",
    "        df['polarity'] = df.text.apply(get_sentiment)\n",
    "        df['polarity_svm'] = df.text.apply(get_sentiment_svm)\n",
    "        \n",
    "        df = df.sort_values('date')\n",
    "        dates = df['date']\n",
    "        emotion = df['polarity']\n",
    "        emotion_svm = df['polarity_svm']\n",
    "        data_tweet = df[['text','polarity','polarity_svm']].tail(10)\n",
    "        print(data_tweet)\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=[8,4])\n",
    "        plt.plot(dates, emotion, 'o', label = 'emotions')\n",
    "        plt.plot(dates, emotion_svm, '*', label = 'emotions_svm')\n",
    "        date_format = mdates.DateFormatter('%m/%d')\n",
    "        plt.gca().xaxis.set_major_formatter(date_format)\n",
    "        plt.xticks(rotation = 30)\n",
    "        plt.ylim([-0.25, 1.25])\n",
    "        plt.legend(['txtb','svm'])\n",
    "        plt.grid()\n",
    "        \n",
    "        plt.savefig('static/images/new_plot.png')\n",
    "        \n",
    "        plt.clf()\n",
    "        from wordcloud import WordCloud\n",
    "        wordcloud = WordCloud().generate(' '.join(df.text_prep))\n",
    "\n",
    "        plt.figure(figsize=[15,8])\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.savefig('static/images/cloud_plot.png')\n",
    "        \n",
    "        \n",
    "        #print(df.tail(10))\n",
    "        \n",
    "        rawtext = topic\n",
    "        blob = TextBlob(rawtext)\n",
    "        received_text2 = blob\n",
    "        blob_sentiment,blob_subjectivity = blob.sentiment.polarity ,blob.sentiment.subjectivity\n",
    "        number_of_tokens = len(list(blob.words))\n",
    "        \n",
    "        # Extracting Main Points\n",
    "        nouns = list()\n",
    "        for word, tag in blob.tags:\n",
    "            if tag == 'NN':\n",
    "                nouns.append(word.lemmatize())\n",
    "                len_of_words = len(nouns)\n",
    "                rand_words = random.sample(nouns,len(nouns))\n",
    "                final_word = list()\n",
    "                for item in rand_words:\n",
    "                    word = Word(item).pluralize()\n",
    "                    final_word.append(word)\n",
    "                    summary = final_word\n",
    "                    end = time.time()\n",
    "                    final_time = round(end-start,2)\n",
    "\n",
    "\n",
    "    return render_template('index.html',received_text = received_text2,n_twwets = len(df),data=data_tweet.to_dict(orient='records'),final_time=final_time, name = 'Sentiment plot', url ='/static/images/new_plot.png', url_wc ='/static/images/cloud_plot.png' )\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f5c2ea-d115-4f43-9f5a-7c5fd58b212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.100.9:5000/ (Press CTRL+C to quit)\n",
      "192.168.100.9 - - [20/Aug/2021 18:43:52] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:43:52] \"\u001b[33mGET /alt=%22Chart_wc%22 HTTP/1.1\u001b[0m\" 404 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:43:52] \"\u001b[33mGET /alt=%22Chart%22 HTTP/1.1\u001b[0m\" 404 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:44:12] \"\u001b[36mGET /static/images/new_plot.png HTTP/1.1\u001b[0m\" 304 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:44:13] \"\u001b[36mGET /static/images/new_plot.png HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  polarity  polarity_svm\n",
      "9  RT @charliespiering: At 1:00 pm Biden will del...         1             1\n",
      "8  RT @larryelder: So Biden’s VP is visiting Saig...         1             1\n",
      "7  RT @CBSNews: WATCH: A small, crying baby was p...         0             1\n",
      "6  RT @CBSNews: WATCH: A small, crying baby was p...         0             1\n",
      "5  RT @CrazyTrain88217: #DemCast\\nPresident Biden...         1             1\n",
      "4  RT @CBSThisMorning: The Biden administration w...         1             1\n",
      "3  @serena_patriot Expensive ass cult, ain't it? ...         0             1\n",
      "2  RT @CBSNews: Marines tend to children in Afgha...         0             1\n",
      "1  SUNDAY: Former U.S. Ambassador to the United N...         1             1\n",
      "0  RT @charliespiering: At 1:00 pm Biden will del...         1             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.100.9 - - [20/Aug/2021 18:45:29] \"POST /analyse HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:45:29] \"GET /static/images/cloud_plot.png HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:45:29] \"GET /static/images/new_plot.png HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  polarity  polarity_svm\n",
      "9  RT @sanofi: We are excited to announce that Sa...         1             1\n",
      "8  🇮🇳  #IndiaAt75 | On #IndependenceDay, we take ...         1             1\n",
      "7  RT @sportstarweb: 🇮🇳  #IndiaAt75 | On #Indepen...         1             1\n",
      "6  RT @sportstarweb: 🇮🇳  #IndiaAt75 | On #Indepen...         1             1\n",
      "5  RT @48hours: Germany's coach for the modern pe...         1             1\n",
      "4  RT @Tokyo2020: The #ClosingCeremony for the Ol...         1             1\n",
      "3  RT @Tokyo_gov: Today, the Olympic Games #Tokyo...         1             1\n",
      "2  @NULOOKREFINISH @legitgov 24,000 kids to be ja...         1             1\n",
      "1  GameStop Deal of the Day [$37.99]: Mario and S...         1             1\n",
      "0  RT @JoaquimCampa: Olympic Games 2024 https://t...         1             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.100.9 - - [20/Aug/2021 18:46:53] \"POST /analyse HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:46:53] \"GET /static/images/cloud_plot.png HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:46:53] \"GET /static/images/new_plot.png HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  polarity  polarity_svm\n",
      "9  A free shuttle will transport SAU students to ...         1             1\n",
      "8  RT @CityLittleRock: COVID VACCINE CLINIC - Pfi...         1             1\n",
      "7  RT @KenyaMedics_KMA: NEXT #TUESDAY\\nYou are in...         1             1\n",
      "6  RT @CityLittleRock: COVID VACCINE CLINIC - Pfi...         1             1\n",
      "5  @ZankFrappa2 @ToadonaWire @ChristinaPushaw Pfi...         1             0\n",
      "4  RT @CityLittleRock: COVID VACCINE CLINIC - Pfi...         1             1\n",
      "3  RT @CityLittleRock: COVID VACCINE CLINIC - Pfi...         1             1\n",
      "2  It's a #SuperSunday #Vaccination at @WatfordFC...         1             1\n",
      "1  RT @Turmaine: It's a #SuperSunday #Vaccination...         1             1\n",
      "0  RT @haskins_shelly: @maggieNYT Lot a lies to u...         1             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.100.9 - - [20/Aug/2021 18:58:06] \"POST /analyse HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:58:06] \"GET /static/images/new_plot.png HTTP/1.1\" 200 -\n",
      "192.168.100.9 - - [20/Aug/2021 18:58:06] \"GET /static/images/cloud_plot.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "from time import sleep\n",
    "sleep(1)\n",
    "\n",
    "import threading\n",
    "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':5000}).start()\n",
    "\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e1a2a-ceef-4d01-a4b0-1b8a8ffe305c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
