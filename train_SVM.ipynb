{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f15cde-dd00-477c-a5c6-5d6f0df2b147",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelo con Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751fcd9b-2b68-4eed-a273-4a3ce86e8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ac4b42-8d23-4243-944e-ceab0b18feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64499638-1db4-49ff-be5d-b5a0badecfd2",
   "metadata": {},
   "source": [
    "### Obtención de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7415ac-6baf-4d2a-9348-341d4d1635b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman Sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damn the person who stolde my wallet !!!!!  Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars Pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>@Calumfan1 is it in any way related to photosh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>@Swiz_NZ really? wow thats crap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>At the 2010 lexus HS250h press event.  Again, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>@karmicunderpath ooooh now there's a nice thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>@mariap91 i'd usually ask you about the sun an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitts  sentiment\n",
       "0           @robbiebronniman Sounds like a great night.           1\n",
       "1      Damn the person who stolde my wallet !!!!!  Ma...          1\n",
       "2      Greetings from the piano bench  (photo) http:/...          1\n",
       "3      @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4      @kissthestars Pretty pretty pretty please, pak...          0\n",
       "...                                                  ...        ...\n",
       "29995  @Calumfan1 is it in any way related to photosh...          0\n",
       "29996                   @Swiz_NZ really? wow thats crap           0\n",
       "29997  At the 2010 lexus HS250h press event.  Again, ...          0\n",
       "29998  @karmicunderpath ooooh now there's a nice thou...          1\n",
       "29999  @mariap91 i'd usually ask you about the sun an...          1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/twitter-data/master/twitt30k.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c0b64-b6b1-480e-9702-08dfe646cb04",
   "metadata": {},
   "source": [
    "### Preprocesameinto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b082ceaf-200a-4802-8647-3e9b6ff950c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prep(text:str):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    \n",
    "    tokens = [] \n",
    "    text = re.sub('https\\S+', '', text)\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "\n",
    "    text = regrex_pattern.sub(r'',text)\n",
    "    #text = re.sub('Replying to \\n@\\S+', '', text)\n",
    "    text = re.sub('RT @\\S+', '', text)\n",
    "    text = re.sub('@\\S+', '', text)\n",
    "    text = re.sub('#\\S+', '', text)\n",
    "\n",
    "    for w in word_tokenize(text):\n",
    "        w = w.lower()\n",
    "        if ((re.search('[a-zA-Z]', w)) and (w not in stopwords)): tokens.append(w)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68193e77-ed2a-4933-bd07-e6a64f61a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98512d13-fae0-4ad6-b48b-3957afe94d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_prep'] = df.twitts.apply(text_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faccf084-d149-4ec0-8c29-5027ad3ecc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29990</th>\n",
       "      <td>@DavidArchie yeah! probably its because of tho...</td>\n",
       "      <td>1</td>\n",
       "      <td>yeah probably cats hate cats especially start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29991</th>\n",
       "      <td>you go girl!!! write like your heart depends o...</td>\n",
       "      <td>1</td>\n",
       "      <td>go girl write like heart depends flippin fanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>I'm recieving alot of shocking news one shot ....</td>\n",
       "      <td>0</td>\n",
       "      <td>'m recieving alot shocking news one shot http ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>Sometimes I even fascinate myself... As I stum...</td>\n",
       "      <td>1</td>\n",
       "      <td>sometimes even fascinate stumle happily home a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>On my way to jons</td>\n",
       "      <td>1</td>\n",
       "      <td>way jons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>@Calumfan1 is it in any way related to photosh...</td>\n",
       "      <td>0</td>\n",
       "      <td>way related photoshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>@Swiz_NZ really? wow thats crap</td>\n",
       "      <td>0</td>\n",
       "      <td>really wow thats crap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>At the 2010 lexus HS250h press event.  Again, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lexus hs250h press event ca n't tell anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>@karmicunderpath ooooh now there's a nice thou...</td>\n",
       "      <td>1</td>\n",
       "      <td>ooooh 's nice thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>@mariap91 i'd usually ask you about the sun an...</td>\n",
       "      <td>1</td>\n",
       "      <td>'d usually ask sun school since write words of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitts  sentiment  \\\n",
       "29990  @DavidArchie yeah! probably its because of tho...          1   \n",
       "29991  you go girl!!! write like your heart depends o...          1   \n",
       "29992  I'm recieving alot of shocking news one shot ....          0   \n",
       "29993  Sometimes I even fascinate myself... As I stum...          1   \n",
       "29994                                 On my way to jons           1   \n",
       "29995  @Calumfan1 is it in any way related to photosh...          0   \n",
       "29996                   @Swiz_NZ really? wow thats crap           0   \n",
       "29997  At the 2010 lexus HS250h press event.  Again, ...          0   \n",
       "29998  @karmicunderpath ooooh now there's a nice thou...          1   \n",
       "29999  @mariap91 i'd usually ask you about the sun an...          1   \n",
       "\n",
       "                                               text_prep  \n",
       "29990  yeah probably cats hate cats especially start ...  \n",
       "29991  go girl write like heart depends flippin fanta...  \n",
       "29992  'm recieving alot shocking news one shot http ...  \n",
       "29993  sometimes even fascinate stumle happily home a...  \n",
       "29994                                           way jons  \n",
       "29995                              way related photoshop  \n",
       "29996                              really wow thats crap  \n",
       "29997  lexus hs250h press event ca n't tell anything ...  \n",
       "29998                              ooooh 's nice thought  \n",
       "29999  'd usually ask sun school since write words of...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983baedb-3e27-48ff-874a-a32e96f6a341",
   "metadata": {},
   "source": [
    "### Entrenamiento con svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1257c1d3-5a5d-455b-be94-c5612709035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(df):\n",
    "    X = df['text_prep']\n",
    "    y = df['sentiment']\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "\n",
    "    print('shape of X: ', X.shape)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print()\n",
    "    print('Printing Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return tfidf, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53c9bd6-2ab6-4bf4-ab00-9674c89785f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 27184)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73      3000\n",
      "           1       0.73      0.74      0.73      3000\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.73      0.73      0.73      6000\n",
      "weighted avg       0.73      0.73      0.73      6000\n",
      "\n",
      "CPU times: user 1.19 s, sys: 24.2 ms, total: 1.21 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf, clf = run_svm(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf77f3-f4b4-4014-a615-16e629bffc40",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "931465bc-3cdc-4e7e-a3b6-e8859d57044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['i am really happy. thanks a lot for coming with me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "280ec444-7a83-4d43-bef8-7ed0cc6e19cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea8f13-74cb-4ef5-a9e7-53a3553a6713",
   "metadata": {},
   "source": [
    "## Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77c718c8-a6d0-472d-803a-578f6f7cbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open('clf.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152f903-6724-4787-a45a-1df32c197532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
